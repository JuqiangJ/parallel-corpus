## Applications

The Parallel Audiobook Corpus was prepared mainly with two scenarios in mind: Speech Synthesis and Voice Conversion.

In the context of Speech Synthesis, this type of data could be useful, for example, for prosody analysis and/or evaluation. Some speakers read the stories or simulate character voices in different ways. Multiple readings of the same textual source can be useful to compare overall prosodic variation across speakers.

In the context of Voice Conversion, parallel data is essential for robust acoustic models. The segmented version of this data is conveniently prepared for this scenario. Matching utterance IDs across multiple speakers will result in a large parallel corpus for average voice models. See `utt2spk` for readings across speakers.

These are, of course, many other possibilities. Feel free to use the data according to your interests. I would be happy to hear about the various scenarios you might use this data for.